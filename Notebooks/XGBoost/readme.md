# Notebooks XGBoost â€“ Projet COVID-19

Ce dossier regroupe lâ€™ensemble des notebooks du **projet COVID-19**, organisÃ©s de 1 Ã  7.  
Ils couvrent toute la chaÃ®ne : analyse, crÃ©ation des datasets, preprocessing, tests de modÃ¨les, sÃ©lection et optimisation XGBoost, puis interprÃ©tation avec SHAP.

---

## ğŸ“˜ 1. Analyse du jeu de donnÃ©es
`1-Analyse.ipynb`

AprÃ¨s analyse du jeu de donnÃ©es, nous avons constatÃ© que la **rÃ©solution des images** peut fortement influencer :

- la consommation mÃ©moire,
- le temps de calcul,
- les performances du modÃ¨le.

Pour cela, lâ€™Ã©tude propose de **crÃ©er plusieurs datasets** selon diffÃ©rentes tailles dâ€™images afin dâ€™observer lâ€™impact de la rÃ©solution sur la prÃ©cision et lâ€™efficacitÃ© du modÃ¨le.

---

## ğŸ“˜ 2. GÃ©nÃ©ration des datasets
`2-GÃ©nÃ©ration_Dataset.ipynb`

Construction du dataset complet Ã  partir des images brutes des **quatre classes**.  
Objectifs :

- crÃ©er plusieurs versions du dataset : **64Ã—64, 128Ã—128, etc.**
- permettre la comparaison des performances des modÃ¨les selon la rÃ©solution
- vÃ©rifier si une taille dâ€™image donne un meilleur compromis entre vitesse et prÃ©cision

---

## ğŸ“˜ 3. PrÃ©-processing
`3-Pre-processing.ipynb`

Pour chaque taille dâ€™image, plusieurs traitements ont Ã©tÃ© appliquÃ©s :

- **CLAHE** : amÃ©lioration du contraste pour faire ressortir les dÃ©tails
- **HOG** : extraction des contours et de la structure globale de lâ€™image
- **Split** du dataset en train/test
- **Normalisation** pour Ã©viter toute fuite de donnÃ©es

Objectif : prÃ©parer les images pour une classification supervisÃ©e robuste.

---

## ğŸ“˜ 4. Test de plusieurs modÃ¨les
`4-Test_plusieurs_modeles.ipynb`

Ã‰valuation initiale de plusieurs modÃ¨les de classification :

- Random Forest  
- Logistic Regression  
- XGBoost (
- Autres modÃ¨les supervisÃ©s

But : sÃ©lectionner le modÃ¨le le plus prometteur et comparer leur comportement sur les diffÃ©rentes rÃ©solutions dâ€™images.

---

## ğŸ“˜ 5. SÃ©lection du modÃ¨le
`5-Selection_modele.ipynb`

AprÃ¨s comparaison, **XGBoost** est retenu comme modÃ¨le principal.  
Cette Ã©tape comprend :

- Interpretation : EquilibrÃ©/Sur-apprentissage/Sous-apprentissage
- Filtrage pour Equilibrage faible/Solide
- Affinage (On garde les modÃ¨les avec un Ã©cart < 0.02)

Objectif : confirmer le choix du meilleur modÃ¨le avant optimisation.

---

## ğŸ“˜ 6. Optimisation XGBoost
`6-Optimisation_XGB`

Optimisation du modÃ¨le en deux approches :

### ğŸ” 1. Exploration  
- variation du **learning rate** pour comprendre la dynamique du modÃ¨le  
- observation des performances selon plusieurs valeurs

### âš™ï¸ 2. Exploitation (tuning)  
- variation du **max_depth**  
- application dâ€™un **poids spÃ©cifique Ã  la classe COVID** afin dâ€™inciter le modÃ¨le Ã  mieux prÃ©dire cette classe, en augmentant sa sensibilitÃ© sur les patients COVID positifs.
- objectif : **maximiser le F1-score**, particuliÃ¨rement critique en diagnostic mÃ©dical

---

## ğŸ“˜ 7. Analyse SHAP (InterprÃ©tabilitÃ©)
`7-Bonus_SHAP_XGB.ipynb`

Analyse avancÃ©e du modÃ¨le XGBoost avec SHAP :  
- **distribution des valeurs SHAP** (positives, nÃ©gatives, neutres)  
- **SHAP global** (importance moyenne des features)  
- **summary_plot**  
- **force_plot** (impact des features sur une prÃ©diction individuelle)

Objectif : comprendre comment chaque variable contribue Ã  la prÃ©diction COVID / non-COVID.

---

## ğŸ“¦ Fichier supplÃ©mentaire
### `requirements.txt`
Liste des dÃ©pendances nÃ©cessaires pour exÃ©cuter lâ€™ensemble des notebooks.

---

## ğŸ¯ Objectif du dossier
Centraliser tous les notebooks du projet COVID, permettant de suivre clairement chaque Ã©tape :  
de lâ€™analyse des donnÃ©es Ã  lâ€™interprÃ©tation finale du modÃ¨le optimisÃ© XGBoost.

