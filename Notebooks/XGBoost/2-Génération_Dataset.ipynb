{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "efb78ee1-c594-45fc-81af-45e9e8f63f04",
   "metadata": {},
   "source": [
    "## üß© Importation des biblioth√®ques principales\n",
    "\n",
    "Cette premi√®re cellule regroupe l‚Äôensemble des **modules n√©cessaires** pour la cr√©ation et la gestion du dataset.  \n",
    "Chaque biblioth√®que joue un r√¥le pr√©cis :\n",
    "\n",
    "- **os** ‚Üí gestion des fichiers et dossiers  \n",
    "- **cv2 (OpenCV)** ‚Üí traitement et transformation des images  \n",
    "- **numpy (np)** ‚Üí manipulation de tableaux et op√©rations matricielles  \n",
    "- **pandas (pd)** ‚Üí cr√©ation et gestion des DataFrames (donn√©es tabulaires)  \n",
    "- **itertools.product** ‚Üí parcourir efficacement toutes les tailles d‚Äôimages sans multiplier les boucles.  \n",
    "- **tqdm** ‚Üí affichage de barres de progression dans les boucles\n",
    "\n",
    "> ‚öôÔ∏è Cette √©tape initialise l‚Äôenvironnement Python n√©cessaire avant le chargement et le traitement des images.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "63ab72ef-fe2b-4d40-beb4-ab5d55b77429",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from itertools import product\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e722285b-61bc-49d2-8ead-a7e59a794968",
   "metadata": {},
   "source": [
    "## üèóÔ∏è G√©n√©ration du Dataset √† diff√©rentes tailles d‚Äôimages\n",
    "\n",
    "Dans cette √©tape, nous allons **construire le dataset complet** √† partir des images brutes des quatre classes disponibles.  \n",
    "L‚Äôobjectif est de cr√©er plusieurs versions du dataset selon diff√©rentes **tailles d‚Äôimages** (64√ó64, 128√ó128, etc.) pour comparer les performances des mod√®les en fonction de la r√©solution.\n",
    "\n",
    "---\n",
    "\n",
    "### ‚öôÔ∏è √âtapes du traitement\n",
    "\n",
    "1. **Initialisation des structures de stockage**\n",
    "   - `X_dict` : contient les *features* (les images transform√©es et aplaties)\n",
    "   - `y_dict` : contient les *labels* (la classe associ√©e √† chaque image)\n",
    "   - `df_dict` : contiendra les DataFrames finaux avant la sauvegarde\n",
    "\n",
    "2. **D√©finition des classes et √©quilibre**\n",
    "   - Les cat√©gories utilis√©es sont :  \n",
    "     - `0 ‚Üí Normal`  \n",
    "     - `1 ‚Üí COVID`  \n",
    "     - `2 ‚Üí Autres pathologies (Lung Opacity et Viral Pneumonia)`  \n",
    "   - Pour √©viter tout **d√©s√©quilibre entre les classes** :  \n",
    "     - On choisit **le m√™me nombre d‚Äôimages pour Normal et COVID**.  \n",
    "     - Les images de Lung Opacity et Viral Pneumonia sont regroup√©es dans la classe `2`, avec un nombre d‚Äôimages total √©quivalent aux autres classes.  \n",
    "   - R√©sultat : **toutes les classes ont le m√™me nombre d‚Äôimages**, garantissant un dataset √©quilibr√©.\n",
    "     \n",
    "\n",
    "3. **Pr√©paration et allocation m√©moire**\n",
    "   - Allocation de tableaux `NumPy` adapt√©s √† la taille d‚Äôimage et au nombre total d‚Äô√©chantillons.\n",
    "   - Permet d‚Äô√©viter les ralentissements dus √† la cr√©ation dynamique de tableaux pendant la boucle.\n",
    "\n",
    "4. **Boucle principale**\n",
    "   - Pour chaque **taille d‚Äôimage** :  \n",
    "     - Lecture et redimensionnement des images et masques (`cv2.resize`)  \n",
    "     - Application d‚Äôun **masquage** (`cv2.bitwise_and`) pour ne conserver que la zone utile  \n",
    "     - Aplatissement des images pour les stocker sous forme de vecteurs  \n",
    "     - Enregistrement des labels correspondants\n",
    "\n",
    "5. **Cr√©ation du DataFrame final**\n",
    "   - Conversion des tableaux `X` et `y` en un `DataFrame Pandas`  \n",
    "   - M√©lange al√©atoire des lignes (`sample(frac=1)`) pour √©viter tout biais d‚Äôordre  \n",
    "   - Sauvegarde du dataset en **format HDF5** (`to_hdf`) pour une lecture rapide et efficace lors de l‚Äôentra√Ænement\n",
    "\n",
    "---\n",
    "\n",
    "### üíæ Sorties g√©n√©r√©es\n",
    "\n",
    "Pour chaque taille d‚Äôimage, un fichier est produit, avec **un nombre √©quilibr√© d‚Äôimages par classe**.  \n",
    "Cela garantit que les mod√®les ne seront pas influenc√©s par une sur-repr√©sentation d‚Äôune classe particuli√®re, ce qui est essentiel pour un apprentissage fiable et repr√©sentatif.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a990ba26-f909-4aea-ba1a-f21707298f3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Traitement des images pour taille 64x64 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3610it [00:14, 249.87it/s]\n",
      "3610it [00:13, 268.12it/s]\n",
      "2268it [00:08, 275.39it/s]\n",
      "1342it [00:05, 242.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Traitement des images pour taille 128x128 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3610it [00:13, 264.24it/s]\n",
      "3610it [00:13, 271.90it/s]\n",
      "2268it [00:07, 291.85it/s]\n",
      "1342it [00:05, 264.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Traitement des images pour taille 176x176 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3610it [00:13, 267.17it/s]\n",
      "3610it [00:13, 261.19it/s]\n",
      "2268it [00:08, 267.24it/s]\n",
      "1342it [00:05, 254.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Traitement des images pour taille 224x224 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3610it [00:15, 240.17it/s]\n",
      "3610it [00:15, 238.76it/s]\n",
      "2268it [00:09, 251.83it/s]\n",
      "1342it [00:06, 202.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Traitement des images pour taille 299x299 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3610it [00:15, 238.28it/s]\n",
      "3610it [00:15, 225.87it/s]\n",
      "2268it [00:09, 231.72it/s]\n",
      "1342it [00:06, 223.04it/s]\n"
     ]
    }
   ],
   "source": [
    "# === Initialisation ===\n",
    "X_dict = {}   # Dictionnaire qui contiendra les images (features)\n",
    "y_dict = {}   # Dictionnaire qui contiendra les labels\n",
    "df_dict = {}  # Dictionnaire pour stocker les DataFrames finaux\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Nous allons generer les datasets du jeu avec les diff√©rentes tailles\n",
    "# === Remarque ===\n",
    "# Nous allons garder des images pour le test via Streamlit \n",
    "# qui n'ont pas √©t√© vues par le mod√®le.\n",
    "# R√©servation : \n",
    "# - 6 images pour les classes Normal et COVID\n",
    "# - 3 images pour les classes Lung_Opacity et Viral Pneumonia\n",
    "classes = {\n",
    "          0: [\"Normal/images\", \"Normal/masks\",3610,0],\n",
    "          1: [\"COVID/images\", \"COVID/masks\",3610,1],\n",
    "          2: [\"Lung_Opacity/images\", \"Lung_Opacity/masks\",2268,2],\n",
    "          3: [\"Viral Pneumonia/images\", \"Viral Pneumonia/masks\",1342,2],\n",
    "}\n",
    "\n",
    "Nb=10830 # Nombre total d'images (somme des sous-ensembles)\n",
    "tailles = [64,128,176,224,299]  # Diff√©rentes tailles √† g√©n√©rer\n",
    "\n",
    "# Pr√©-allocation m√©moire\n",
    "X_dict[Nb]={}\n",
    "y_dict[Nb]={}\n",
    "df_dict[Nb]={}\n",
    "\n",
    "\n",
    "for size in tailles:\n",
    "    X_dict[Nb][size] = np.zeros((Nb, size * size), dtype=np.uint8)\n",
    "    y_dict[Nb][size] = np.zeros((Nb,), dtype=np.uint8)\n",
    "\n",
    "\t\n",
    "for lot, taille in product([10830], tailles):\n",
    "    index_global = 0\n",
    "    print(f\"\\n=== Traitement des images pour taille {taille}x{taille} ===\")\n",
    "    \n",
    "    for indice ,(img,mask,num,classe) in classes.items():\n",
    "        contenu_image=os.listdir(img)\n",
    "        contenu_mask=os.listdir(mask)\n",
    "        for i,(imag,masks) in tqdm(enumerate(zip(contenu_image[:num],contenu_mask[:num]))):\n",
    "            # Lecture et redimension\n",
    "            img_covid4=cv2.imread(os.path.join(img,imag),cv2.IMREAD_GRAYSCALE)\n",
    "            mask_covid4=cv2.imread(os.path.join(mask,masks),cv2.IMREAD_GRAYSCALE)\n",
    "            \n",
    "            if img_covid4 is None or mask_covid4 is None:\n",
    "                continue  # s√©curit√© en cas d‚Äôimage corrompue\n",
    "                \n",
    "            img_resize=cv2.resize(img_covid4,dsize=(taille,taille))\n",
    "            mask_resize=cv2.resize(mask_covid4,dsize=(taille,taille))\n",
    "         \n",
    "            # Fusion image + masque\n",
    "            melange_covid4=cv2.bitwise_and(img_resize,mask_resize)\n",
    "            \n",
    "            \n",
    "            # Donn√©es avec les images aplatie dans X et cible dans y\n",
    "            X_dict[lot][taille][index_global,:] = melange_covid4.reshape(-1)\n",
    "            y_dict[lot][taille][index_global]=classe\n",
    "            index_global += 1\n",
    "                \n",
    "    # Cr√©ation DataFrame final\n",
    "    df=pd.DataFrame(X_dict[lot][taille])\n",
    "    df[\"Cible\"]=y_dict[lot][taille]\n",
    "    df.columns =df.columns.map(str)\n",
    "    \n",
    "    \n",
    "    # M√©lange al√©atoire\n",
    "    df=df.sample(frac=1,random_state=42).reset_index(drop=True)\n",
    "    \n",
    "    \n",
    "    # Sauvegarde en HDF5\n",
    "    filename = f\"dataset_{taille}_{Nb}.h5\"\n",
    "    df.to_hdf(filename, key=f\"df_{taille}_{Nb}\", mode=\"w\", format=\"fixed\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dcfa83c-53b6-435a-90e7-99d7ca7952db",
   "metadata": {},
   "source": [
    "## üìÇ Chargement et v√©rification des datasets HDF5\n",
    "\n",
    "Une fois les diff√©rents datasets cr√©√©s et sauvegard√©s au format **HDF5**, nous les rechargeons ici pour v√©rifier leur **int√©grit√©** et **√©quilibre des classes**.\n",
    "\n",
    "---\n",
    "\n",
    "### ‚öôÔ∏è √âtapes effectu√©es\n",
    "\n",
    "1. **Chargement des fichiers**\n",
    "   - Pour chaque taille d‚Äôimage (64√ó64, 128√ó128, 176√ó176, 224√ó224, 299√ó299), le fichier correspondant est charg√© depuis le disque :\n",
    "     ```\n",
    "     dataset_<taille>_10830.h5\n",
    "     ```\n",
    "   - Le contenu est lu via la cl√© :\n",
    "     ```\n",
    "     df_<taille>_10830\n",
    "     ```\n",
    "   - Chaque DataFrame est stock√© dans le dictionnaire `dfs` pour un acc√®s facile selon la taille.\n",
    "\n",
    "2. **V√©rification de la r√©partition des classes**\n",
    "   - Pour chaque DataFrame, la distribution de la colonne **`Cible`** (les labels de classes) est affich√©e.\n",
    "   - Cela permet de confirmer :\n",
    "     - qu‚Äôaucune image n‚Äôa √©t√© perdue pendant la g√©n√©ration,\n",
    "     - que les classes sont bien √©quilibr√©es (ou de rep√©rer un √©ventuel d√©s√©quilibre).\n",
    "\n",
    "---\n",
    "\n",
    "### üßæ Exemple de sortie attendue\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "60d9c437-f37f-404b-bc51-73e4d4a1f83b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====v√©rification de l'equilibre des classes pour la taille 64x64:\n",
      "Cible\n",
      "0    3610\n",
      "2    3610\n",
      "1    3610\n",
      "Name: count, dtype: int64\n",
      "====v√©rification de l'equilibre des classes pour la taille 128x128:\n",
      "Cible\n",
      "0    3610\n",
      "2    3610\n",
      "1    3610\n",
      "Name: count, dtype: int64\n",
      "====v√©rification de l'equilibre des classes pour la taille 176x176:\n",
      "Cible\n",
      "0    3610\n",
      "2    3610\n",
      "1    3610\n",
      "Name: count, dtype: int64\n",
      "====v√©rification de l'equilibre des classes pour la taille 224x224:\n",
      "Cible\n",
      "0    3610\n",
      "2    3610\n",
      "1    3610\n",
      "Name: count, dtype: int64\n",
      "====v√©rification de l'equilibre des classes pour la taille 299x299:\n",
      "Cible\n",
      "0    3610\n",
      "2    3610\n",
      "1    3610\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# === Lecture du Dataframe depuis HDF5 ===\n",
    "dfs={}\n",
    "tailles = [64,128,176,224,299]\n",
    "for t in tailles:\n",
    "    filename=f\"dataset_{t}_10830.h5\"\n",
    "    key=f\"df_{t}_10830\"\n",
    "    dfs[t]=pd.read_hdf(filename,key=key)\n",
    "    \n",
    "for t in tailles:\n",
    "    print(f\"====v√©rification de l'equilibre des classes pour la taille {t}x{t}:\")\n",
    "    print(dfs[t][\"Cible\"].value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "846eb340-b59c-4173-8b7f-b17f66b8bf30",
   "metadata": {},
   "source": [
    "## üßÆ V√©rification des dimensions des DataFrames\n",
    "\n",
    "Apr√®s avoir confirm√© l‚Äô√©quilibre des classes, il est essentiel de v√©rifier la **structure** de chaque DataFrame pour s‚Äôassurer que :\n",
    "\n",
    "- le **nombre total de lignes** correspond bien au total d‚Äôimages attendu,  \n",
    "- le **nombre de colonnes** (features extraites + colonne cible) est coh√©rent entre les diff√©rentes tailles d‚Äôimages.\n",
    "\n",
    "---\n",
    "\n",
    "### ‚öôÔ∏è √âtapes effectu√©es\n",
    "\n",
    "Pour chaque taille d‚Äôimage (`64x64`, `128x128`, `176x176`, `224x224`, `299x299`) :\n",
    "- On affiche le r√©sultat de la m√©thode `shape`, qui retourne :\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3afb0ec1-88dd-4624-85ac-d5d930429629",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====v√©rification des lignes et colonnes pour chaques classes pour la taille 64x64:\n",
      "(10830, 4097)\n",
      "====v√©rification des lignes et colonnes pour chaques classes pour la taille 128x128:\n",
      "(10830, 16385)\n",
      "====v√©rification des lignes et colonnes pour chaques classes pour la taille 176x176:\n",
      "(10830, 30977)\n",
      "====v√©rification des lignes et colonnes pour chaques classes pour la taille 224x224:\n",
      "(10830, 50177)\n",
      "====v√©rification des lignes et colonnes pour chaques classes pour la taille 299x299:\n",
      "(10830, 89402)\n"
     ]
    }
   ],
   "source": [
    "for t in tailles:\n",
    "    print(f\"====v√©rification des lignes et colonnes pour chaques classes pour la taille {t}x{t}:\")\n",
    "    print(dfs[t].shape)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3acea8d5-f0db-43a8-8d56-7b72ba55f549",
   "metadata": {},
   "source": [
    "## ‚úÖ Conclusion : Validation des jeux de donn√©es\n",
    "\n",
    "Les diff√©rents datasets g√©n√©r√©s pr√©sentent les caract√©ristiques suivantes :\n",
    "\n",
    "- **Coh√©rence structurelle :**  \n",
    "  Chaque DataFrame poss√®de le bon nombre de lignes et de colonnes selon la taille d‚Äôimage choisie.\n",
    "\n",
    "- **√âquilibre des classes :**  \n",
    "  Les classes sont r√©parties de mani√®re homog√®ne, garantissant une bonne repr√©sentativit√© lors de l‚Äôentra√Ænement.\n",
    "\n",
    "- **Disponibilit√© multi-tailles :**  \n",
    "  Les jeux de donn√©es sont disponibles pour plusieurs r√©solutions (`64x64`, `128x128`, `176x176`, `224x224`, `299x299`), ce qui permettra de comparer les performances des mod√®les selon la taille des images.\n",
    "\n",
    "---\n",
    "\n",
    "üí° **Conclusion finale :**  \n",
    "Ces datasets sont **coh√©rents**, **√©quilibr√©s** et **pr√™ts pour le pr√©traitement** ainsi que pour **l‚Äôapprentissage des mod√®les**.  \n",
    "Si un ralentissement se fait sentir, nous pourrons **r√©duire le nombre d‚Äôimages** utilis√©es pour acc√©l√©rer les exp√©rimentations sans compromettre la validit√© des r√©sultats.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
