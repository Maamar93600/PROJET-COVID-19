{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "27649a71-cce8-4c48-8d70-527b117cbbb3",
   "metadata": {},
   "source": [
    "### ðŸ§© PrÃ©paration et importation des bibliothÃ¨ques\n",
    "\n",
    "Dans cette section, nous importons les bibliothÃ¨ques nÃ©cessaires au **prÃ©traitement des images** et Ã  la **prÃ©paration des donnÃ©es** pour lâ€™apprentissage automatique :\n",
    "\n",
    "- **NumPy** â†’ pour la manipulation efficace des tableaux et calculs numÃ©riques.  \n",
    "- **OpenCV (`cv2`)** â†’ pour le traitement dâ€™images (lecture, redimensionnement, filtres, etc.).  \n",
    "- **`hog` (Histogram of Oriented Gradients)** â†’ pour lâ€™extraction des caractÃ©ristiques visuelles (bords, textures, orientations).  \n",
    "- **`StandardScaler`** â†’ pour normaliser les donnÃ©es et amÃ©liorer la convergence des modÃ¨les.  \n",
    "- **`train_test_split`** â†’ pour sÃ©parer le jeu de donnÃ©es en ensembles dâ€™entraÃ®nement et de test.  \n",
    "- **`gc`** â†’ pour libÃ©rer la mÃ©moire aprÃ¨s les traitements intensifs.  \n",
    "- **`joblib`** â†’ pour sauvegarder et charger efficacement les objets Python volumineux (datasets, modÃ¨les, etc.).\n",
    "- **`Pandas`** â†’ pour la manipulation avancÃ©e de donnÃ©es tabulaires, le chargement de datasets, la crÃ©ation de DataFrames, lâ€™exploration, le nettoyage, les jointures et la prÃ©paration des donnÃ©es avant lâ€™entraÃ®nement des modÃ¨les.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "317d6c64-2db2-40e4-8115-fb465556a423",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from skimage.feature import hog\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import gc\n",
    "import joblib\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5818cbb8-330e-4348-a0b7-86aeb1c6bbe8",
   "metadata": {},
   "source": [
    "### ðŸ“‚ Lecture des datasets HDF5\n",
    "\n",
    "Dans cette Ã©tape, nous rechargeons les datasets prÃ©cÃ©demment gÃ©nÃ©rÃ©s pour chaque **taille dâ€™image** afin de prÃ©parer le prÃ©traitement :\n",
    "\n",
    "- Chaque fichier HDF5 est identifiÃ© par : dataset_\"taille\"_10830.h5\n",
    "\n",
    "- La clÃ© utilisÃ©e pour accÃ©der au DataFrame est : df_\"taille\"_10830\n",
    "\n",
    "- Les DataFrames sont stockÃ©s dans le dictionnaire `dfs` pour un accÃ¨s facile selon la taille des images.\n",
    "\n",
    "> âš¡ Objectif : avoir tous les datasets en mÃ©moire, prÃªts pour lâ€™extraction des features (HOG) et la normalisation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b3ec0f29-eb8a-41bb-ada8-6521951e6427",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Lecture du Dataframe depuis HDF5 ===\n",
    "dfs={}\n",
    "tailles = [64,128,176,224,299]\n",
    "\n",
    "for t in tailles:\n",
    "    filename=f\"dataset_{t}_10830.h5\"\n",
    "    key=f\"df_{t}_10830\"\n",
    "    dfs[t]=pd.read_hdf(filename,key=key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9409219c-e72b-420b-9fe7-12cc0a2e9826",
   "metadata": {},
   "source": [
    "### 3ï¸âƒ£ PrÃ©traitement des images, extraction HOG et crÃ©ation des splits\n",
    "- Cette cellule effectue plusieurs Ã©tapes importantesâ€¯:\n",
    "    1. DÃ©finition des paramÃ¨tres HOG et CLAHE pour chaque taille dâ€™image.\n",
    "    2. Calcul dynamique de la longueur du vecteur HOG selon la taille de lâ€™image, la taille des cellules, des blocs et le nombre dâ€™orientations.\n",
    "    3. Application de CLAHE sur chaque image pour amÃ©liorer le contraste.\n",
    "    4. Extraction des caractÃ©ristiques HOG pour chaque image.\n",
    "    5. Standardisation des vecteurs de caractÃ©ristiques avec StandardScaler.\n",
    "    6. SÃ©paration train/test avec stratification\n",
    "    - On utilise `stratify=y_array` pour maintenir la proportion de chaque classe dans lâ€™ensemble dâ€™entraÃ®nement et de test.\n",
    "    - Cela permet dâ€™Ã©viter un dÃ©sÃ©quilibre dans les splits et dâ€™obtenir des mÃ©triques plus fiables lors de lâ€™Ã©valuation des modÃ¨les.\n",
    "\n",
    "\n",
    "    7. Sauvegarde des splits dans des fichiers .pkl pour chaque taille dâ€™image.\n",
    "\n",
    "ðŸ’¡ Remarque importanteâ€¯: la taille du vecteur HOG varie selon la taille de lâ€™image et le paramÃ©trage des cellules/blocs afin dâ€™avoir un compromis entre dÃ©tails de lâ€™image et longueur du vecteur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3683c7e3-e73a-4c4e-a3c4-de12cf938ee5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Taille 64 ---\n",
      "âœ… Taille 64 terminÃ©e et sauvegardÃ©e â†’ splits_64.pkl\n",
      "Taille 64 terminÃ©e. Train shape: (8664, 1764), Test shape: (2166, 1764)\n",
      "\n",
      "--- Taille 128 ---\n",
      "âœ… Taille 128 terminÃ©e et sauvegardÃ©e â†’ splits_128.pkl\n",
      "Taille 128 terminÃ©e. Train shape: (8664, 2916), Test shape: (2166, 2916)\n",
      "\n",
      "--- Taille 176 ---\n",
      "âœ… Taille 176 terminÃ©e et sauvegardÃ©e â†’ splits_176.pkl\n",
      "Taille 176 terminÃ©e. Train shape: (8664, 4356), Test shape: (2166, 4356)\n",
      "\n",
      "--- Taille 224 ---\n",
      "âœ… Taille 224 terminÃ©e et sauvegardÃ©e â†’ splits_224.pkl\n",
      "Taille 224 terminÃ©e. Train shape: (8664, 10404), Test shape: (2166, 10404)\n",
      "\n",
      "--- Taille 299 ---\n",
      "âœ… Taille 299 terminÃ©e et sauvegardÃ©e â†’ splits_299.pkl\n",
      "Taille 299 terminÃ©e. Train shape: (8664, 7569), Test shape: (2166, 7569)\n"
     ]
    }
   ],
   "source": [
    "# ParamÃ¨tres pour chaque taille d'image\n",
    "params_dict = {\n",
    "    64:  {'clahe_clip': 2, 'clahe_grid': (2,2), 'cell': 8,  'bloc': 2, 'orien': 9},\n",
    "    128: {'clahe_clip': 2, 'clahe_grid': (4,4), 'cell': 12, 'bloc': 2, 'orien': 9},\n",
    "    176: {'clahe_clip': 2, 'clahe_grid': (5,5), 'cell': 14, 'bloc': 2, 'orien': 9},\n",
    "    224: {'clahe_clip': 2, 'clahe_grid': (6,6), 'cell': 12, 'bloc': 2, 'orien': 9},\n",
    "    299: {'clahe_clip': 2, 'clahe_grid': (8,8), 'cell': 10, 'bloc': 1, 'orien': 9}\n",
    "}\n",
    "\n",
    "\n",
    "# === Dictionnaires pour stockage - train/test split de chaque taille ===\n",
    "splits = {}\n",
    "\n",
    "# Fonction HOG\n",
    "def extract_hog_features(image,hog_cell,hog_bloc,orien):\n",
    "    features=hog(image,orientations=orien,\n",
    "        pixels_per_cell=(hog_cell,hog_cell),\n",
    "        cells_per_block=(hog_bloc,hog_bloc),\n",
    "        block_norm='L2-Hys',\n",
    "        visualize=False)\n",
    "    return features\n",
    "\n",
    "def hog_vector_length(img_size, cell, bloc, orien):\n",
    "    n_cells_x = img_size // cell\n",
    "    n_cells_y = img_size // cell\n",
    "    n_blocks_x = n_cells_x - bloc + 1\n",
    "    n_blocks_y = n_cells_y - bloc + 1\n",
    "    length = n_blocks_x * n_blocks_y * (bloc ** 2) * orien\n",
    "    return length\n",
    "\n",
    "    \n",
    "# === Boucle principale sur les tailles ===\n",
    "for size in [64,128,176,224,299]:\n",
    "    print(f\"\\n--- Taille {size} ---\")\n",
    "\n",
    "    # SÃ©paration des donnÃ©es\n",
    "    df=dfs[size]\n",
    "    X_pixels = df.drop(columns=\"Cible\").to_numpy(dtype=np.uint8)\n",
    "    y_array = df[\"Cible\"].to_numpy(dtype=np.int32)\n",
    "    Nb = len(df)\n",
    "\n",
    "    length = hog_vector_length(size, params_dict[size]['cell'], params_dict[size]['bloc'], params_dict[size]['orien'])\n",
    "    \n",
    "    # PrÃ©paration arrays\n",
    "    X_array = np.zeros((Nb, length), dtype=np.float32)\n",
    "\n",
    "    # Boucle sur chaque image pour HOG \n",
    "    for idx, img in enumerate(X_pixels):\n",
    "        \n",
    "        # CLAHE augmentation\n",
    "        clahe = cv2.createCLAHE(clipLimit=params_dict[size]['clahe_clip'],tileGridSize=params_dict[size]['clahe_grid'])\n",
    "        img_clahe = clahe.apply(img.reshape(size,size))\n",
    "        \n",
    "           \n",
    "    \n",
    "        # Calcul HOG et retour de l'image â€œHOG visualisÃ©eâ€\n",
    "        features=extract_hog_features(img_clahe,params_dict[size][\"cell\"],params_dict[size][\"bloc\"], params_dict[size][\"orien\"])\n",
    "        X_array[idx, :] = features\n",
    "    \n",
    "    \n",
    "    # StandardScaler avec split pour Ã©viter fuite\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_array, y_array, test_size=0.2, random_state=42, stratify=y_array)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train).astype(np.float32)\n",
    "    X_test_scaled  = scaler.transform(X_test).astype(np.float32)\n",
    "    \n",
    "    # Stockage\n",
    "    splits[size] = {\n",
    "        \"X_train\": X_train_scaled,\n",
    "        \"X_test\": X_test_scaled,\n",
    "        \"y_train\": y_train,\n",
    "        \"y_test\": y_test}\n",
    "\n",
    "    # Sauvegarde de chaque taille sÃ©parÃ©ment\n",
    "    joblib.dump(splits[size], f\"splits_{size}.pkl\", compress=3)\n",
    "    print(f\"âœ… Taille {size} terminÃ©e et sauvegardÃ©e â†’ splits_{size}.pkl\")\n",
    "\n",
    "    \n",
    "    \n",
    "    print(f\"Taille {size} terminÃ©e. Train shape: {X_train_scaled.shape}, Test shape: {X_test_scaled.shape}\")\n",
    "\n",
    "    # LibÃ©ration mÃ©moire\n",
    "    del splits[size],X_array, X_train, X_test, X_train_scaled, X_test_scaled\n",
    "    gc.collect()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "add2ec7c-ddf6-46bc-9856-89a1cd05589f",
   "metadata": {},
   "source": [
    "### Conclusion sur les vecteurs HOG\n",
    "\n",
    "On peut remarquer que le vecteur HOG pour les images plus petites que 224 est plus court, car les paramÃ¨tres sont adaptÃ©s Ã  la taille de lâ€™image.  \n",
    "\n",
    "La taille des cellules et des blocs est choisie pour Ã©quilibrer le dÃ©tail capturÃ© et la longueur du vecteurâ€¯:  \n",
    "\n",
    "- Des cellules trop petites donnent trop de valeurs et un vecteur trÃ¨s long.  \n",
    "- Des cellules trop grandes fournissent moins de gradients et un vecteur trop court.  \n",
    "\n",
    "Pour les grandes images, on augmente la taille des cellules et ajuste les blocs afin de capturer suffisamment de dÃ©tails sans rendre le vecteur HOG trop volumineux.\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸš€ Passage Ã  lâ€™entraÃ®nement et Ã  lâ€™Ã©valuation des modÃ¨les\n",
    "\n",
    "Les datasets sont dÃ©sormais **prÃ©traitÃ©s, normalisÃ©s et sÃ©parÃ©s en train/test** pour chaque taille dâ€™image.  \n",
    "\n",
    "Dans le notebook suivant, nous allons :  \n",
    "\n",
    "1. Charger ces splits sauvegardÃ©s (`.pkl`) pour chaque taille.  \n",
    "2. Tester plusieurs modÃ¨les classiques et avancÃ©s (SVM, RandomForest, GradientBoosting, XGBoost, MLP, etc.).  \n",
    "3. Comparer les **scores dâ€™entraÃ®nement et de test** pour identifier :  \n",
    "   - Les modÃ¨les susceptibles de **surdapprentissage** (train trÃ¨s haut, test faible)  \n",
    "   - Les modÃ¨les en **sous-apprentissage** (scores faibles sur train et test)  \n",
    "   - Les modÃ¨les **Ã©quilibrÃ©s** offrant de bonnes performances gÃ©nÃ©rales  \n",
    "\n",
    "> ðŸŽ¯ Objectif : choisir le modÃ¨le le plus adaptÃ© Ã  nos donnÃ©es avant de passer Ã  lâ€™optimisation fine des hyperparamÃ¨tres.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
