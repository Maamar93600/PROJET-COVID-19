{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad15e24b-0421-4ba3-8c5f-99df138f8575",
   "metadata": {},
   "source": [
    "## üß† Importation des biblioth√®ques pour la mod√©lisation\n",
    "\n",
    "Dans cette cellule, nous importons toutes les biblioth√®ques n√©cessaires pour tester diff√©rents mod√®les d‚Äôapprentissage automatique sur nos datasets HOG.\n",
    "\n",
    "### Mod√®les import√©s :\n",
    "\n",
    "- **Arbres de d√©cision et ensembles** :\n",
    "  - `DecisionTreeClassifier` ‚Üí arbre de d√©cision simple  \n",
    "  - `RandomForestClassifier` ‚Üí for√™t al√©atoire  \n",
    "  - `ExtraTreesClassifier` ‚Üí for√™t extr√™mement al√©atoire  \n",
    "  - `GradientBoostingClassifier` ‚Üí gradient boosting classique  \n",
    "  - `HistGradientBoostingClassifier` ‚Üí version optimis√©e pour grands datasets  \n",
    "\n",
    "- **SVM et r√©gression** :\n",
    "  - `SVC` ‚Üí support vector classifier  \n",
    "  - `LogisticRegression` ‚Üí r√©gression logistique  \n",
    "\n",
    "- **Autres mod√®les** :\n",
    "  - `KNeighborsClassifier` ‚Üí k-plus proches voisins  \n",
    "  - `MLPClassifier` ‚Üí perceptron multi-couches (r√©seau de neurones simple)  \n",
    "  - `XGBClassifier` ‚Üí XGBoost, boosting bas√© sur les arbres  \n",
    "\n",
    "### Utilitaires :\n",
    "\n",
    "- `pandas` ‚Üí manipulation de DataFrame pour stocker et analyser les r√©sultats  \n",
    "- `joblib` ‚Üí sauvegarde et chargement des splits et mod√®les  \n",
    "- `time` ‚Üí mesurer le temps d‚Äôentra√Ænement  \n",
    "- `tqdm` ‚Üí barre de progression pour les boucles\n",
    "\n",
    "> ‚ö° Objectif : disposer de tous les mod√®les et outils n√©cessaires pour √©valuer leurs performances sur nos datasets HOG.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "64e3fb96-3119-4de7-a6fa-bffbe58141fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier,ExtraTreesClassifier,HistGradientBoostingClassifier,GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import time\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73f3326f-ca64-4f61-86fd-b42266a3a216",
   "metadata": {},
   "source": [
    "## üìÇ Chargement des splits pr√©trait√©s\n",
    "\n",
    "Dans cette cellule, nous chargeons les fichiers `.pkl` sauvegard√©s pr√©c√©demment pour chaque taille d‚Äôimage.  \n",
    "\n",
    "Chaque fichier contient :  \n",
    "- `X_train` : vecteurs de caract√©ristiques HOG normalis√©s pour l‚Äôentra√Ænement  \n",
    "- `X_test`  : vecteurs de caract√©ristiques HOG normalis√©s pour le test  \n",
    "- `y_train` : labels d‚Äôentra√Ænement  \n",
    "- `y_test`  : labels de test  \n",
    "\n",
    "Ces splits sont stock√©s dans un dictionnaire `split` index√© par la taille de l‚Äôimage, ce qui permet de **travailler facilement sur diff√©rentes r√©solutions** :\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e412a29e-1ec2-445b-9585-8b5a62696654",
   "metadata": {},
   "outputs": [],
   "source": [
    "split={}\n",
    "tailles = [64,128,176,224,299]\n",
    "for t in tailles:\n",
    "    filename=f\"splits_{t}.pkl\"\n",
    "    split[t]=joblib.load(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad7156fc-88ca-4984-a1db-837200f37b24",
   "metadata": {},
   "source": [
    "## üß© D√©finition des mod√®les √† tester\n",
    "\n",
    "Dans cette cellule, nous pr√©parons tous les mod√®les que nous allons entra√Æner et √©valuer sur nos vecteurs HOG.  \n",
    "L‚Äôobjectif est de comparer les performances et de voir quels mod√®les sont les plus adapt√©s √† notre dataset.\n",
    "\n",
    "### Mod√®les classiques\n",
    "Ces mod√®les n‚Äôutilisent pas d‚Äôarbres et sont adapt√©s pour des vecteurs de caract√©ristiques denses‚ÄØ:  \n",
    "- **SVC** : Support Vector Classifier  \n",
    "- **KNN** : k-plus proches voisins  \n",
    "- **MLP** : r√©seau de neurones simple avec deux couches cach√©es  \n",
    "- **Logistic Regression** : r√©gression logistique classique  \n",
    "\n",
    "### Mod√®les bas√©s sur les arbres\n",
    "Ces mod√®les utilisent des arbres de d√©cision simples ou des ensembles d‚Äôarbres pour am√©liorer les performances‚ÄØ:  \n",
    "- **DecisionTree** : arbre de d√©cision simple  \n",
    "- **RandomForest** : for√™t al√©atoire, r√©duction de la variance gr√¢ce au bagging  \n",
    "- **ExtraTrees** : for√™t extr√™mement al√©atoire  \n",
    "- **GradientBoosting** : gradient boosting classique, r√©duction du biais  \n",
    "- **XGBoost** : version optimis√©e de gradient boosting, adapt√©e aux grands datasets  \n",
    "\n",
    "> üí° Remarque : Cette distinction entre mod√®les classiques et arbres permet de comparer facilement **diff√©rents types de mod√®les** et de s√©lectionner ceux qui offrent le meilleur compromis entre biais, variance et performances.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a54d3b83-74df-4c6e-8d31-03326278d9c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === D√©finition des mod√®les classiques  ===\n",
    "model_classiques={\n",
    "     \"SVC\": SVC(),\n",
    "     \"KNN\": KNeighborsClassifier(),\n",
    "     \"MLP\": MLPClassifier(hidden_layer_sizes=(128, 64), max_iter=300, random_state=42),\n",
    "     \"LR\": LogisticRegression(max_iter=10000, solver='lbfgs')}\n",
    "\n",
    "# === D√©finition des mod√®les arbres  ===\n",
    "model_arbres = {\n",
    "    \"DecisionTree\": DecisionTreeClassifier(random_state=42),\n",
    "    \"RandomForest\": RandomForestClassifier(n_jobs=-1, random_state=42),\n",
    "    \"ExtraTrees\": ExtraTreesClassifier(n_jobs=-1, random_state=42),\n",
    "    \"GradientBoosting\": GradientBoostingClassifier(random_state=42),\n",
    "    \"XGB\": XGBClassifier(n_jobs=-1,  eval_metric='mlogloss')\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c60f3282-749d-486e-b919-b31a2b0d1729",
   "metadata": {},
   "source": [
    "## üèÉ‚Äç‚ôÇÔ∏è Exp√©rimentation et √©valuation des mod√®les\n",
    "\n",
    "Cette cellule effectue les tests de performance pour tous les mod√®les d√©finis pr√©c√©demment, sur diff√©rentes tailles d‚Äôimages et diff√©rents sous-ensembles d‚Äô√©chantillons.  \n",
    "\n",
    "### √âtapes principales\n",
    "\n",
    "1. **D√©finition des tailles et √©chantillons**  \n",
    "   - Tailles des images : 64, 128, 176, 224, 299  \n",
    "   - Nombre d‚Äôimages pour l‚Äôentra√Ænement : 1664, 2664, 4664, 6664, 8664  \n",
    "\n",
    "2. **S√©lection des mod√®les**  \n",
    "   - `Classique` : SVC, KNN, MLP, LogisticRegression  \n",
    "   - `Arbre` : DecisionTree, RandomForest, ExtraTrees, GradientBoosting, XGBoost  \n",
    "\n",
    "3. **Boucle d‚Äôexp√©rimentation**  \n",
    "   - Pour chaque type de mod√®le (`Classique` ou `Arbre`)  \n",
    "   - Pour chaque taille d‚Äô√©chantillon  \n",
    "   - Pour chaque taille d‚Äôimage  \n",
    "\n",
    "4. **Pr√©paration des donn√©es**  \n",
    "   - Chargement des splits train/test correspondants  \n",
    "   - Test **sur toutes les tailles d‚Äô√©chantillons** pour observer si la quantit√© de donn√©es impacte les scores ou non  \n",
    "\n",
    "5. **Entra√Ænement et √©valuation**  \n",
    "   - Entra√Ænement de chaque mod√®le sur le sous-√©chantillon correspondant  \n",
    "   - Calcul du **score sur l‚Äôensemble d‚Äôentra√Ænement** (`score_train`)  \n",
    "   - Calcul du **score sur l‚Äôensemble de test** (`score_test`)  \n",
    "   - Mesure du **temps d‚Äôentra√Ænement** pour chaque mod√®le  \n",
    "   - ‚ö†Ô∏è Remarque : certaines √©tapes peuvent prendre beaucoup de temps selon le mod√®le et la taille des images. Des red√©marrages ou r√©initialisations ont parfois √©t√© n√©cessaires pour √©viter que le notebook ne reste bloqu√©.  \n",
    "\n",
    "6. **Stockage des r√©sultats**  \n",
    "   - Tous les r√©sultats sont ajout√©s √† une liste `resultat`  \n",
    "   - Sauvegarde interm√©diaire en CSV apr√®s chaque taille d‚Äô√©chantillon pour √©viter toute perte  \n",
    "\n",
    "> ‚ö° Objectif : obtenir un **tableau complet des performances** pour chaque mod√®le, chaque taille d‚Äôimage et chaque nombre d‚Äô√©chantillons, afin de comparer efficacement **biais, variance et temps d‚Äôentra√Ænement**, et observer l‚Äôinfluence du nombre d‚Äôimages sur les scores.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4596eb20-a68b-4396-bec2-dfe5edfb514e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================== Tests des mod√®les ARBRE ====================\n",
      "\n",
      "\n",
      "=== Traitement pour 8664 images ===\n",
      "\n",
      "=== Traitement pour la Taille 64x64 ===\n",
      "\n",
      "=== Traitement du model DecisionTree ===\n",
      "\n",
      "=== Traitement du model RandomForest ===\n",
      "\n",
      "=== Traitement du model ExtraTrees ===\n",
      "\n",
      "=== Traitement du model GradientBoosting ===\n",
      "\n",
      "=== Traitement du model XGB ===\n",
      "\n",
      "=== Traitement pour la Taille 128x128 ===\n",
      "\n",
      "=== Traitement du model DecisionTree ===\n",
      "\n",
      "=== Traitement du model RandomForest ===\n",
      "\n",
      "=== Traitement du model ExtraTrees ===\n",
      "\n",
      "=== Traitement du model GradientBoosting ===\n",
      "\n",
      "=== Traitement du model XGB ===\n",
      "\n",
      "=== Traitement pour la Taille 176x176 ===\n",
      "\n",
      "=== Traitement du model DecisionTree ===\n",
      "\n",
      "=== Traitement du model RandomForest ===\n",
      "\n",
      "=== Traitement du model ExtraTrees ===\n",
      "\n",
      "=== Traitement du model GradientBoosting ===\n",
      "\n",
      "=== Traitement du model XGB ===\n",
      "\n",
      "=== Traitement pour la Taille 224x224 ===\n",
      "\n",
      "=== Traitement du model DecisionTree ===\n",
      "\n",
      "=== Traitement du model RandomForest ===\n",
      "\n",
      "=== Traitement du model ExtraTrees ===\n",
      "\n",
      "=== Traitement du model GradientBoosting ===\n",
      "\n",
      "=== Traitement du model XGB ===\n",
      "\n",
      "=== Traitement pour la Taille 299x299 ===\n",
      "\n",
      "=== Traitement du model DecisionTree ===\n",
      "\n",
      "=== Traitement du model RandomForest ===\n",
      "\n",
      "=== Traitement du model ExtraTrees ===\n",
      "\n",
      "=== Traitement du model GradientBoosting ===\n",
      "\n",
      "=== Traitement du model XGB ===\n",
      "\n",
      " Sauvegarde interm√©diaire : resultats_modeles_24102025_bis_Arbre_8664.csv\n"
     ]
    }
   ],
   "source": [
    "resultat=[]\n",
    "\n",
    "# === Listes des tailles et √©chantillons ===\n",
    "tailles = [64,128,176,224,299]\n",
    "sample=[1664,2664,4664,6664,8664]\n",
    "\n",
    "models = {\n",
    "    \"Classique\": model_classiques,\n",
    "    \"Arbre\": model_arbres\n",
    "}\n",
    "\n",
    "for type_modele, dico in models.items():\n",
    "    \n",
    "    print(f\"\\n==================== Tests des mod√®les {type_modele.upper()} ====================\\n\")\n",
    "    \n",
    "    # === Boucles d‚Äôexp√©rimentation ===\n",
    "    for s in sample:\n",
    "        print(f\"\\n=== Traitement pour {s} images ===\")\n",
    "           \n",
    "        for taille in tailles:\n",
    "            print(f\"\\n=== Traitement pour la Taille {taille}x{taille} ===\")\n",
    "            X_train_scaled=split[taille][\"X_train\"]\n",
    "            X_test_scaled=split[taille][\"X_test\"]\n",
    "            y_train=split[taille][\"y_train\"]\n",
    "            y_test=split[taille][\"y_test\"]\n",
    "        \n",
    "            # ‚úÖ R√©duction du jeu d'entra√Ænement si n√©cessaire\n",
    "            n = min(s, len(X_train_scaled))\n",
    "            X_train_sub = X_train_scaled[:n]\n",
    "            y_train_sub = y_train[:n]\n",
    "        \n",
    "            # === Entra√Ænement et mesure de performance ===\n",
    "            for clf_name,clf in dico.items():\n",
    "                print(f\"\\n=== Traitement du model {clf_name} ===\")\n",
    "                start = time.time()\n",
    "                clf.fit(X_train_sub,y_train_sub)\n",
    "                duration = time.time() - start\n",
    "        \n",
    "                score_train=clf.score(X_train_sub,y_train_sub)\n",
    "                score_test=clf.score(X_test_scaled,y_test)\n",
    "                \n",
    "                resultat.append({\"Type\": type_modele,\"sample\":n,\"taille\":taille,\"clf\":clf_name,\"score_train\":round(score_train,4),\"score_test\":round(score_test,4),\"Temps(s)\":round(duration,2)})\n",
    "    \n",
    "        # sauvegarde de s√©curit√© apr√®s chaque taille d‚Äô√©chantillon\n",
    "        pd.DataFrame(resultat).to_csv(f\"resultats_modeles_{type_modele}_{s}.csv\", index=False)\n",
    "        print(f\"\\n Sauvegarde interm√©diaire : resultats_modeles_{type_modele}_{s}.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e1ada4aa-82cf-46c3-8caa-09389ff20b05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score_train</th>\n",
       "      <th>score_test</th>\n",
       "      <th>Temps(s)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>clf</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>DecisionTree</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.514604</td>\n",
       "      <td>22.1452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ExtraTrees</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.695844</td>\n",
       "      <td>1.9712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GradientBoosting</th>\n",
       "      <td>0.915268</td>\n",
       "      <td>0.710836</td>\n",
       "      <td>1640.7248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNN</th>\n",
       "      <td>0.747336</td>\n",
       "      <td>0.623692</td>\n",
       "      <td>0.0144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR</th>\n",
       "      <td>0.993328</td>\n",
       "      <td>0.667204</td>\n",
       "      <td>3.8416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.743372</td>\n",
       "      <td>15.0468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForest</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.691880</td>\n",
       "      <td>3.6944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVC</th>\n",
       "      <td>0.918276</td>\n",
       "      <td>0.735008</td>\n",
       "      <td>334.7444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGB</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.737008</td>\n",
       "      <td>90.8952</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  score_train  score_test   Temps(s)\n",
       "clf                                                 \n",
       "DecisionTree         1.000000    0.514604    22.1452\n",
       "ExtraTrees           1.000000    0.695844     1.9712\n",
       "GradientBoosting     0.915268    0.710836  1640.7248\n",
       "KNN                  0.747336    0.623692     0.0144\n",
       "LR                   0.993328    0.667204     3.8416\n",
       "MLP                  1.000000    0.743372    15.0468\n",
       "RandomForest         1.000000    0.691880     3.6944\n",
       "SVC                  0.918276    0.735008   334.7444\n",
       "XGB                  1.000000    0.737008    90.8952"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# === R√©sultats finaux sous forme de DataFrame ===\n",
    "df_resultats = pd.read_csv(\"resultats_modeles_final.csv\")\n",
    "resum√©=df_resultats.groupby(\"clf\").agg({'score_train': 'mean', 'score_test': 'mean',\"Temps(s)\":'mean'})\n",
    "display(resum√©)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30ca5449-cb10-408c-a91c-09704b8de521",
   "metadata": {},
   "source": [
    "## üìä R√©sultats finaux\n",
    "\n",
    "Dans cette cellule, nous centralisons tous les r√©sultats des exp√©rimentations dans un **DataFrame final**.  \n",
    "\n",
    "- Lecture du fichier `resultats_modeles_final.csv` contenant tous les scores obtenus pour chaque mod√®le, chaque taille d‚Äôimage et chaque taille d‚Äô√©chantillon.  \n",
    "- Calcul des **scores moyens** sur l‚Äôensemble d‚Äôentra√Ænement (`score_train`) et de test (`score_test`) pour chaque mod√®le.  \n",
    "- Calcul du **temps moyen d‚Äôentra√Ænement** (`Temps(s)`) pour chaque mod√®le afin d‚Äôavoir une id√©e de la performance en termes de rapidit√©.\n",
    "\n",
    "> üí° Cette √©tape permet de **r√©sumer rapidement les performances globales** et le temps n√©cessaire pour chaque mod√®le avant de passer √† l‚Äôanalyse approfondie.  \n",
    "> \n",
    "> La prochaine √©tape se fera dans le notebook **d‚Äôinterpr√©tation des mod√®les**, o√π nous analyserons les √©carts entre train et test, identifierons les mod√®les sous- ou sur-appris, et d√©terminerons ceux qui sont les plus adapt√©s pour notre dataset, tout en prenant en compte leur temps d‚Äôex√©cution.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
